version: "3.8"

## Port Assignments:
##  See .env file

## Container debugging:
# 1. append the following lines to desired container
# 2. boot up the container using `docker-compose up -d`
# 3 run `docker exec -it <container-name> bash` to start interactive shell
#
#    tty: true
#    stdin_open: true
#    entrypoint: bash

## Utility for booting up placeholder page:
# `docker run --hostname openhim-placeholder --network shared-health-record_sedish --name openhim-placeholder -e MESSAGE=OPENHIM-PLACEHOLDER -e PORT=3000 -d docker.io/sroze/landing-page:latest`

services:
  ###
  # nginx reverse proxy
  # TODO: set up to use non-root user. See https://www.rockyourcode.com/run-docker-nginx-as-non-root-user/
  ###
  # nginx:
  #   image: nginx:latest
  #   container_name: nginx
  #   hostname: nginx
  #   restart: unless-stopped
  #   ports:
  #     - "80:80" # OpenHIM Console
  #     - "443:443" # OpenHIM Console
  #     - "8080:8080" # OpenHIM Core API
  #     - "5000:5000" # OpenHIM HTTPS
  #     - "5001:5001" # OpenHIM HTTP
  #     - "3000:3000" # OpenCR
  #     - "8000:8000" # iSantePlus
  #   volumes:
  #     - ./configs/nginx/nginx.ports.conf:/etc/nginx/nginx.conf
  #     - nginx-data:/var/www
  #     - ./configs/nginx/healthcheck.sh:/healthcheck.sh
  #     - certs:/etc/ssl/
  #   networks:
  #     - sedish
  #   healthcheck:
  #     test: ["CMD-SHELL", "/healthcheck.sh"]
  #     interval: 10s
  #     timeout: 1m
  #     retries: 100
  # #     start_period: 3m
  # certgen:
  #   image: magnitus/certificate-generator:latest
  #   environment:
  #     COUNTRY: US
  #     STATE: WA
  #     CITY: SEATTLE
  #     ORGANIZATION: I-TECH-UW
  #     DEPARTMENT: DIGI
  #     EMAIL: cert@sedish-heaiti.org
  #     DOMAINS: dev.mydomain.com;test.mydomain.com;localhost
  #     CERTIFICATE_DURATION: 11095
  #     OUTPUT_CERTIFICATE_INFO: "true"
  #     KEY_FILE: "ports.key"
  #     CERTIFICATE_FILE: "ports.crt"
  #   volumes:
  #     - certs:/opt/output
  ###
  # OpenCR
  ###
  opencr:
    platform: linux/amd64
    container_name: opencr
    hostname: opencr
    image: intrahealth/opencr:latest
    restart: unless-stopped
    environment:
      - NODE_ENV=docker
      - HAPI_FHIR_URL=http://opencr-fhir:8080/fhir/metadata
    networks:
      - sedish
    volumes:
      - ./configs/opencr/config_ports.json:/src/server/config/config_docker.json
      - ./configs/opencr/mediator_ports.json:/src/server/config/mediator.json
      - ./configs/opencr/decisionRules.json:/src/server/config/decisionRules.json
  opencr-fhir:
    image: "hapiproject/hapi:latest"
    container_name: opencr-fhir
    hostname: opencr-fhir
    restart: unless-stopped
    env_file:
      - configs/opencr/.env
    volumes:
      - /data/hapi
    networks:
      - sedish

  opencr-es:
    container_name: es
    hostname: es
    image: intrahealth/elasticsearch:latest
    restart: unless-stopped
    environment:
      - node.name=es01
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - sedish

  ###
  # SHR
  ###
  shr:
    container_name: shr
    hostname: shr
    image: ghcr.io/i-tech-uw/shared-health-record:v0.4.3
    restart: unless-stopped
    environment:
      - NODE_ENV=docker
    networks:
      - sedish
    volumes:
      - ./configs/shr/config_ports.json:/app/config/config_docker.json
      - ./configs/shr/mediator_ports.json:/app/config/mediator_docker.json

  shr-fhir:
    image: "hapiproject/hapi:latest"
    container_name: shr-fhir
    hostname: shr-fhir
    restart: unless-stopped
    volumes:
      - /data/hapi
    networks:
      - sedish
    env_file:
      - configs/shr/.env
  ####
  # DBs
  ###

  postgres:
    image: postgres
    container_name: postgres
    hostname: postgres
    restart: unless-stopped
    environment:
      POSTGRES_PASSWORD: ${PG_PW}
      POSTGRES_DB: opencr
    volumes:
      - pg-data:/var/lib/postgresql/data/
  
  ####
  # Kafka
  ###
  zookeeper:
    image: "bitnami/zookeeper:latest"
    hostname: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - sedish
  kafka:
    image: "bitnami/kafka:latest"
    hostname: kafka
    container_name: kafka
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka-data1:/bitnami/kafka
    depends_on:
      - zookeeper
    networks:
      - sedish

  ###
  # iSantePlus
  ###
  isanteplus:
    container_name: isanteplus
    hostname: isanteplus
    image: ghcr.io/isanteplus/docker-isanteplus-server:${ISANTEPLUS_DOCKER_VERSION}
    restart: unless-stopped
    env_file:
      - ./configs/isanteplus/isanteplus.env
    volumes:
      - isanteplus-data:/openmrs/data
      - ./configs/isanteplus/custom_modules:/custom_modules
    networks:
      - sedish
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
    labels:
      - traefik.enable=true
      - traefik.http.routers.myapp.tls=true
      - traefik.http.routers.myapp.rule=Host("isanteplus.localhost")

  isanteplus-mysql:
    image: ghcr.io/isanteplus/docker-isanteplus-db:${ISANTEPLUS_DB_VERSION}
    command: mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --sql_mode=""
    restart: unless-stopped
    container_name: isanteplus-mysql
    hostname: isanteplus-mysql
    healthcheck:
      test: "exit 0"
    environment:
      - MYSQL_DATABASE=openmrs
      - MYSQL_ROOT_PASSWORD=debezium
      - MYSQL_USER=mysqluser
      - MYSQL_PASSWORD=mysqlpw
      - MYSQL_ROOT_HOST=% # Allow docker containers to connect to mysql
    volumes:
      - ./configs/isanteplus/mysql.cnf:/etc/mysql/conf.d/custom.cnf # mysql config preconfigured to allow binlog/debezium
      - isanteplus-db-data-alt:/var/lib/mysql
    networks:
    - sedish

  ###
  # OpenHIM
  ###
  openhim-core:
    container_name: openhim-core
    image: jembi/openhim-core:latest
    restart: unless-stopped
    hostname: openhim-core
    environment:
      mongo_url: "mongodb://mongo-db/openhim"
      mongo_atnaUrl: "mongodb://mongo-db/openhim"
      NODE_ENV: "development"
    healthcheck:
      test: "node /healthcheck.js"
      interval: 20s
      timeout: 20s
      retries: 2
    networks:
      - sedish
    labels:
      - traefik.enable=true
      - traefik.http.routers.openhim-core.rule=Host("openhim-core.localhost")
      - traefik.http.routers.openhim-core.tls=true
      - traefik.http.routers.openhim-core.service=openhim-core-service
      - traefik.http.services.openhim-core-service.loadbalancer.server.port=8080
      
      - traefik.http.routers.ssl.rule=Host("openhim-ssl.localhost")
      - traefik.http.routers.ssl.tls=true
      - traefik.http.routers.ssl.service=svc_ssl
      - traefik.http.services.svc_ssl.loadbalancer.server.port=5000
      
      - traefik.http.routers.http.rule=Host("openhim-http.localhost")
      - traefik.http.routers.http.tls=false
      - traefik.http.routers.http.service=svc_http
      - traefik.http.services.svc_http.loadbalancer.server.port=5000
    ports:
      - 8080
    volumes:
      - ./configs/openhim-core/healthcheck.js:/healthcheck.js


  openhim-console:
    container_name: openhim-console
    image: jembi/openhim-console:latest
    restart: unless-stopped
    volumes:
      - ./configs/openhim-console/traefik.json:/usr/share/nginx/html/config/default.json
    healthcheck:
      test: "curl -sS http://openhim-console || exit 1"
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - sedish
    # labels:
    #   - traefik.enable=true
    #   - traefik.http.routers.myapp.tls=true
    #   - traefik.http.routers.myapp.rule=Host("openhim-console.localhost")

  mongo-db:
    container_name: mongo-db
    image: mongo:3.4
    volumes:
      - "mongo-data:/data/db"
    restart: unless-stopped
    networks:
      - sedish

  openhim-config:
    container_name: openhim-config
    image: ghcr.io/i-tech-uw/openhim-config:v0.0.0
    volumes:
      - ./configs/openhim-core/initial-config.json:/app/test-openhim-config.json
    networks:
      - sedish
    environment:
      - INITIAL_PW=openhim-password
      - ADMIN_PW=$ADMIN_PW
      - API_URL=https://openhim-core:8080
  ## SHR Resource Stream
  streaming-pipeline: 
    image: ghcr.io/i-tech-uw/openmrs-fhir-analytics/streaming-binlog:latest
    container_name: streaming-pipeline
    healthcheck:
      test: "exit 0"
    volumes:
      - ./configs/streaming-pipeline/config.json:/deployments/config.json
      # data is the directory which you want to persist the generated parquet files
      # - ./configs/streaming-pipeline/data:/tmp
    environment:
      - OPENMRS_URL=http://isanteplus:8080/openmrs
      - OPENMRS_USERNAME=admin
      - OPENMRS_PASSWORD=Admin123
      - SINK_URL=http://openhim-core:5001/SHR/fhir
      - SINK_USERNAME=shr-pipeline
      - SINK_PASSWORD=shr-pipeline
      - JDBC_FETCH_SIZE=10000
      - JDBC_MAX_POOL_SIZE=50
      - JDBC_INITIAL_POOL_SIZE=10
      - JDBC_DRIVER_CLASS=com.mysql.cj.jdbc.Driver
      # the 2 variable below should be same as volume mappings above
      - PARQUET_PATH=
      - FHIR_DEBEZIUM_CONFIG_PATH=/deployments/config.json
    networks:
      - sedish
  

volumes:
  esdata:
    driver: local
  isanteplus-data:
    driver: local
  isanteplus-db-data:
    driver: local
  isanteplus-db-data-alt:
    driver: local
  mongo-data:
    driver: local
  shr:
    driver: local
  hapi-data:
    driver: local
  cr-data:
    driver: local
  certs:
    driver: local
  letsencrypt:
    driver: local
  nginx-data:
    driver: local
  kafka-data1:
    driver: local
  pg-data:  
    driver: local
networks:
  sedish:
