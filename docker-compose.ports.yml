version: "3.8"

## Port Assignments:
##  See .env file

## Container debugging:
# 1. append the following lines to desired container
# 2. boot up the container using `docker-compose up -d`
# 3 run `docker exec -it <container-name> bash` to start interactive shell
#
#    tty: true
#    stdin_open: true
#    entrypoint: bash

## Utility for booting up placeholder page:
# `docker run --hostname openhim-placeholder --network shared-health-record_sedish --name openhim-placeholder -e MESSAGE=OPENHIM-PLACEHOLDER -e PORT=3000 -d docker.io/sroze/landing-page:latest`

services:
  ###
  # nginx reverse proxy
  # TODO: set up to use non-root user. See https://www.rockyourcode.com/run-docker-nginx-as-non-root-user/
  ###
  nginx:
    image: nginx:latest
    container_name: nginx
    hostname: nginx
    restart: unless-stopped
    ports:
      - "80:80" # OpenHIM Console
      - "443:443" # OpenHIM Console
      - "8080:8080" # OpenHIM Core API
      - "5000:5000" # OpenHIM HTTPS
      - "5001:5001" # OpenHIM HTTP
      - "3000:3000" # OpenCR
      - "8000:8000" # iSantePlus
    volumes:
      - ./configs/nginx/nginx.ports.conf:/etc/nginx/nginx.conf
      - nginx-data:/var/www
      - ./configs/nginx/healthcheck.sh:/healthcheck.sh
      - certs:/etc/ssl/
    networks:
      - sedish
    healthcheck:
      test: ["CMD-SHELL", "/healthcheck.sh"]
      interval: 10s
      timeout: 1m
      retries: 100
      start_period: 3m
  certgen:
    image: magnitus/certificate-generator:latest
    environment:
      COUNTRY: US
      STATE: WA
      CITY: SEATTLE
      ORGANIZATION: I-TECH-UW
      DEPARTMENT: DIGI
      EMAIL: cert@sedish-heaiti.org
      DOMAINS: dev.mydomain.com;test.mydomain.com;localhost
      CERTIFICATE_DURATION: 11095
      OUTPUT_CERTIFICATE_INFO: "true"
      KEY_FILE: "ports.key"
      CERTIFICATE_FILE: "ports.crt"
    volumes:
      - certs:/opt/output
  ###
  # OpenCR
  ###
  opencr:
    platform: linux/amd64
    container_name: opencr
    hostname: opencr
    image: intrahealth/opencr:latest
    restart: unless-stopped
    environment:
      - NODE_ENV=docker
      - HAPI_FHIR_URL=http://opencr-fhir:8080/fhir/metadata
    networks:
      - sedish
    volumes:
      - ./configs/opencr/config_ports.json:/src/server/config/config_docker.json
      - ./configs/opencr/mediator_ports.json:/src/server/config/mediator.json
      - ./configs/opencr/decisionRules.json:/src/server/config/decisionRules.json
  opencr-fhir:
    image: "hapiproject/hapi:latest"
    container_name: opencr-fhir
    hostname: opencr-fhir
    restart: unless-stopped
    env_file:
      - ./configs/opencr/.env
    volumes:
      - cr-data:/data/hapi
    networks:
      - sedish

  opencr-es:
    container_name: es
    hostname: es
    image: intrahealth/elasticsearch:latest
    restart: unless-stopped
    environment:
      - node.name=es01
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - sedish

  ###
  # SHR
  ###
  shr:
    container_name: shr
    hostname: shr
    image: ghcr.io/i-tech-uw/shared-health-record:v0.4.3
    restart: unless-stopped
    environment:
      - NODE_ENV=docker
    networks:
      - sedish
    volumes:
      - ./configs/shr/config_ports.json:/app/config/config_docker.json
      - ./configs/shr/mediator_ports.json:/app/config/mediator_docker.json

  shr-fhir:
    image: "hapiproject/hapi:latest"
    container_name: shr-fhir
    hostname: shr-fhir
    restart: unless-stopped
    volumes:
      - hapi-data:/data/hapi
      - ./configs/shr/application.yml:/data/hapi/application.yaml
    networks:
      - sedish
    environment:
      SPRING_CONFIG_LOCATION: 'file:///data/hapi/application.yaml'


  ####
  # DBs
  ###

  postgres:
    image: postgres
    container_name: postgres
    hostname: postgres
    restart: unless-stopped
    environment:
      POSTGRES_PASSWORD: ${PG_PW}
      POSTGRES_DB: opencr
    volumes:
      - pg-data:/var/lib/postgresql/data/
    networks:
      - sedish

  ####
  # Kafka
  ###
  zookeeper:
    image: "bitnami/zookeeper:latest"
    hostname: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - sedish
  kafka:
    image: "bitnami/kafka:latest"
    hostname: kafka
    container_name: kafka
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka-data1:/bitnami/kafka
    depends_on:
      - zookeeper
    networks:
      - sedish

  ###
  # iSantePlus
  ###
  isanteplus:
    container_name: isanteplus
    hostname: isanteplus
    image: ghcr.io/isanteplus/docker-isanteplus-server:${ISANTEPLUS_DOCKER_VERSION}
    restart: unless-stopped
    env_file:
      - ./configs/isanteplus/isanteplus.env
    volumes:
      - isanteplus-data:/openmrs/data
    networks:
      - sedish
    logging:
      driver: "json-file"
      options:
        max-size: "10m"

  isanteplus-mysql:
    image: ghcr.io/isanteplus/docker-isanteplus-db:main
    command: mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --sql_mode=""
    restart: unless-stopped
    container_name: isanteplus-mysql
    hostname: isanteplus-mysql
    healthcheck:
      test: "exit 0"
    environment:
      - MYSQL_DATABASE=openmrs
      - MYSQL_ROOT_PASSWORD=debezium
      - MYSQL_USER=mysqluser
      - MYSQL_PASSWORD=mysqlpw
      - MYSQL_ROOT_HOST=% # Allow docker containers to connect to mysql
    volumes:
      - ./configs/isanteplus/mysql.cnf:/etc/mysql/conf.d/custom.cnf # mysql config preconfigured to allow binlog/debezium
      - isanteplus-db-data-alt:/var/lib/mysql
    networks:
    - sedish

  ###
  # OpenHIM
  ###
  openhim-core:
    container_name: openhim-core
    image: jembi/openhim-core:latest
    restart: unless-stopped
    environment:
      mongo_url: "mongodb://mongo-db/openhim"
      mongo_atnaUrl: "mongodb://mongo-db/openhim"
      NODE_ENV: "development"
    healthcheck:
      test: "curl -sSk https://localhost:8080/heartbeat || exit 1"
      interval: 2m
      timeout: 1m
      retries: 5
    networks:
      - sedish

  openhim-console:
    container_name: openhim-console
    image: jembi/openhim-console:latest
    restart: unless-stopped
    volumes:
      - ./configs/openhim-console/ports.json:/usr/share/nginx/html/config/default.json
    healthcheck:
      test: "curl -sS http://openhim-console || exit 1"
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - sedish
  openhim-config:
    container_name: openhim-config
    image: ghcr.io/i-tech-uw/openhim-config:v0.0.0
    volumes:
      - ./configs/openhim-core/initial-config.json:/app/test-openhim-config.json
    networks:
      - sedish
    environment:
      - INITIAL_PW=openhim-password
      - ADMIN_PW=$ADMIN_PW
      - API_URL=https://openhim-core:8080
  mongo-db:
    container_name: mongo-db
    image: mongo:3.4
    volumes:
      - "mongo-data:/data/db"
    restart: unless-stopped
    networks:
      - sedish

  ## SHR Resource Stream
  streaming-pipeline: 
    image: ghcr.io/i-tech-uw/openmrs-fhir-analytics/streaming-binlog:latest
    container_name: streaming-pipeline
    healthcheck:
      test: "exit 0"
    volumes:
      - ./configs/streaming-pipeline/config.json:/deployments/config.json
      # data is the directory which you want to persist the generated parquet files
      # - ./configs/streaming-pipeline/data:/tmp
    environment:
      - OPENMRS_URL=http://isanteplus:8080/openmrs
      - OPENMRS_USERNAME=admin
      - OPENMRS_PASSWORD=Admin123
      - SINK_URL=http://openhim-core:5001/SHR/fhir
      - SINK_USERNAME=shr-pipeline
      - SINK_PASSWORD=shr-pipeline
      - JDBC_FETCH_SIZE=10000
      - JDBC_MAX_POOL_SIZE=50
      - JDBC_INITIAL_POOL_SIZE=10
      - JDBC_DRIVER_CLASS=com.mysql.cj.jdbc.Driver
      # the 2 variable below should be same as volume mappings above
      - PARQUET_PATH=
      - FHIR_DEBEZIUM_CONFIG_PATH=/deployments/config.json
    networks:
      - sedish
  # Newman Tests
  newman:
    image: postman/newman
    volumes:
      - ./.postman:/.postman
    entrypoint: newman run $POSTMAN_COLLECTION -e /.postman/postman_env.ci.json --insecure --timeout-request 20000 --delay-request 1000
    networks:
      - sedish

volumes:
  esdata:
    driver: local
  isanteplus-data:
    driver: local
  isanteplus-db-data:
    driver: local
  isanteplus-db-data-alt:
    driver: local
  mongo-data:
    driver: local
  shr:
    driver: local
  hapi-data:
    driver: local
  cr-data:
    driver: local
  certs:
    driver: local
  letsencrypt:
    driver: local
  nginx-data:
    driver: local
  kafka-data1:
    driver: local
  pg-data:
    driver: local
networks:
  sedish:
